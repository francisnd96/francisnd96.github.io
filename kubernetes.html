<!DOCTYPE html>
<html lang="en">
<head>
    <link rel="stylesheet" href="css/custom.css">
</head>
<body>
<div class="container content">
    <div class="masthead"><h3 class="masthead-title"><a href="index.html" title="Home">Francis Nana-Dabankah</a><span
            class="top-nav nav-bar"><span class="top-nav-item"><a href="about.html" title="About">About</a></span> <span
            class="top-nav-item"><a href="projects.html" title="Projects">Projects</a></span> <span class="top-nav-item"><a
            href="contact.html" title="Contact">Contact</a></span> <span class="top-nav-item"><a
            href="blog.html" title="Blog">Blog</a></span> <span class="top-nav-item"><a href="more.html"
                                                                                        title="More">More</a></span></span>
    </h3></div>
    <nav id="breadcrumb-nav" class="nav-bar"><span class="csu-breadcrumb"><a href="index.html">Home</a></span>
        <ol class="csu-breadcrumbs" vocab="http://schema.org/" typeof="BreadcrumbList">
            <li class="csu-breadcrumb active" property="itemListElement" typeof="ListItem"><a property="item"
                                                                                              typeof="WebPage"
                                                                                              href="kubernetes.html"><span
                    property="name">Kubernetes</span></a>
                <meta property="position" content="1">
            </li>
        </ol>
    </nav>
    <div class="page">
        <div class="page-header"><h1 class="page-title"> Kubernetes</h1></div>
        <div class="page-content">
            Kubernetes is a container orchestration platform developed by Google which initially released in 2014. Although it was first developed by Google, it’s now maintained by the Cloud Native Computing Foundation (CNCF). Kubernetes is an open-source platform with more than 67k stars in Github. Some of the basic Kubernetes features are listed below.
            Automate container scaling
            Self-heal containers
            Automatic rollback and rollout
            Storage orchestration
            Container load balancing
            There are many more advanced features available with Kubernetes, but these are the most commonly used features. You can learn a lot more about other features from the official documentation page from here.
            Kubernetes Architecture
            When we start deployment on Kubernetes the first thing we get is a cluster. This Kubernetes cluster contains all the masters, workers, and other components that require for our deployments. On the top level, we can divide a Kubernetes cluster into 3 different components:
            Master nodes
            Worker nodes
            Distributed key-value store (etcd)
            Master Node
            Mater node is responsible for managing the whole Kubernetes cluster. It acts as the main control point for the cluster state and management. For high availability, there can be multiple master nodes, but for administrative tasks, only one will act as a leader.

            Master Node Architecture
            Each master node will have the following components inside it:
            Controller — mange the cluster and make sure current state is matched with the desired state of an application
            API Server — all administrative tasks for the cluster is done through this API server. All CLI, API and dashboard commands are directed to this API server where it will validate the request and execute them
            Scheduler — schedules the work for different worker nodes. Scheduler knows about the currently running applications on each node and knows about the constraints on each worker node. Based on this information, the scheduler assigns the worker node for a deployment/service.
            Worker Node
            A worker node is any machine or a virtual machine within the cluster that runs pods with containers. All the worker nodes are controlled by the master node and have all the information about it. To access the application we need to connect to the worker nodes, not for the master node.

            Worker Node Architecture
            Each worker node contains the following components:
            kube-proxy — network proxy which runs on each worker node and listens to the API server for each endpoint creation or deletion. Kube-proxy creates routes for each endpoint hence kube-proxy is the component that enables communication to worker nodes from within the cluster or from outside.
            kubelet — agent which runs on every worker node which communicates with the master node. It has the responsibility of executing pod execution commands and make sure that pods are always healthy.
            Container Runtime — manage the container lifecycle on the worker node. Kubernetes supports many container runtimes such as Docker, containerd etc..
            Key-value store (etcd)
            Key-value store is used to store information for managing the cluster state. The key-value store is distributed which makes it highly available. All master nodes are connected to it. Key-value store or etcd is written in Go programming language. Apart from storing the state, it also stores configuration details and config maps.
            Interacting with Kubernetes Master nodes is mostly done by an administrative team inside an organization like network admin team or DevOps admin team. Software developers who will deploy applications will have the most interactions with worker nodes. As mentioned earlier, each worker node contains n number of pods.
            Pods
            The logical unit of one or many containers. A container is where our images are loaded and executed. Rather than working with containers, Kubernetes works with pods. So pods are the bottom-most component in Kubernetes architecture. Containers in the same pod share network, storage resources, and lifecycle.
            When created, each pod is assigned a unique IP. Since containers share the network infrastructure in the same pod, this IP address is also shared. And because of that, each container inside the same pod can communicate with each other via the localhost. Below is an example YAML file specification for a pod with one container running Nginx on port 80.

            Deployments
            A deployment is responsible for keeping a set of pods running at a given time. It acts as a management specification for a pod or set of pods that we desire. Deployment is where we specify how many pods at a given time we need running for our application. With this information, Kubernetes will make sure that we have the desired number of pods always.
            Deployments are only responsible for managing identical pods. Without deployment, we need to create, update, or delete pods manually when they fail for some unforeseeable reason, which will be a difficult task. Below is an example of deployments specification which manages our above-defined Nginx pod with specifying we need always two sets of pods running.

            kind = Deployment kind
            metadata: name = Name of the deployment
            spec: replicas = Number of pod replicas we want, in this instances Kubernetes will make sure that we have 2 pods running always
            spec: selector: matchLables = Determine what pods belong to this deployment. This label should be provided when we assign a service for these pods as well
            spec: template= Contains the same information we provided in the pod specification
            spec: template: spec = Define container images name, name, and ports which it will expose from the pod
            Below are some of the common commands we may use with deployments via kubectl:
            #Apply the deployment
            kubectl apply -f deployment.yaml
            #Check deployment progress
            kubectl get deployments test-deployment
            #Update image of the deployment
            kubectl set image deployment/test-deployment nginx=nginx:1.14.1 --record
            #Check rollout status
            kubectl rollout status deployment.v1.apps/test-deployment
            #Get details about the deployment
            kubectl describe deployment test-deployment
            #Rollback to a previouse version
            kubectl rollout undo deployment.v1.apps/test-deployment
            Services
            Services are Kubernetes resources that are configured to give network access to a set of pods. Each service will be automatically assigned a cluster IP which will be used for internal cluster communication. Each pod gets a unique IP address for communication within the cluster, but when a pod gets restarted this IP address will change as well. So services are introduced to abstract these pods by giving a static cluster IP for service, which is independent of pods. There are 4 types of service types available in Kubernetes.
            Cluster IP — Default service type. Will be assigned an internal cluster IP unique to that server. Only reachable within the cluster.
            Node Port — Expose the service on each Node’s IP at a static port which Can be accessed from the external. A unique cluster IP will be also automatically created for internal communication.
            Load Balancer — Expose the service externally by using a cloud provider’s load balancer
            External Name — Map the service to the contents of the external DNS name of a CNAME record.
            As mentioned, services act in front of a set of pods. These pods are determined based on their label. We can run pods without a service as well, in that instance we will need to send requests to each pod individually. But keeping track of these pods will be difficult, hence we abstract it using a service.
            Below is an example specification for a service created as type Cluster IP.

            Above YAML file declares a service which is a type of cluster IP with exposing multiple ports. We have not defined the type as Cluster IP because by default the type will be Cluster IP
            metadata: name = Name of the service
            spec: selector: app = pod labels that this service bind to. It should be matched to deployment matchLabels.
            spec: ports = ports that we are going to expose. Note since the type is Cluster IP these ports are only accessible within the cluster
            spec: ports: tagertPort =container/pod port the application exposed
            spec: ports: port= port that service will expose
            Below is an example specification of a service which is a type of NodePort.

            spec: type = defined as NodePort
            spec: nodePort =optional field. If not specified Kubernetes will allocate a port from range (default: 30000–32767). This will be the port it will be assigned on the node IP which can be accessible from the outside.
            Some common commands for kubectl for applying and getting information about services.
            #Apply service
            kubectl apply -f service.yaml
            #Get details about service(ports and cluster IP)
            kubectl get service nodeport-service
            Kubernetes Network
            After deploying our applications we get to the question of how our container communication between the cluster and outside the cluster is done. Kubernetes have been able to make this complex networking system to less complex for developers. Typically there are 4 types of communications that need to be achieved in a Kubernetes cluster.
            Container to container communication — each container inside the same pod can access each other via the localhost.
            Pod to pod communication — each pod is assigned with a unique IP address within the cluster. Pod to pod communication can be divided in to further two parts. Pod to pod in the same worker node and pod to pod in different worker nodes. In the first type, an ARP request to the root network will give the destination while in the latter using the router table destination will be found.
            Pod to service communication — each service will know each IP address of the pods it is bind to.
            External to service communication- done through the ingress network. Ingress network is a collection of rules that allow connections from external which can be configured to return service. Ingress controllers sit in front of multiple services and act as a smart router.
            Ingress
            Ingress is the most suitable way if you need to expose your application to the external. Ingress network is a collection of rules that allow connections from external which can be configured to return service and it sits in front of multiple services and acts as a smart router.
            In order to create an Ingress resource first, we must have an Ingress controller. We can have multiple ingress controllers running for the same cluster. There are many types of Ingress controllers available for Kubernetes like Google Cloud Load Balancer, Nginx, and Contour. The default ingress controller is GKE. Inside our ingress resource, we need to specify ingress rules. In each rule, we need to specify an optional host, mandatory rule paths, and backends for each path. Each backend will be a service we have already created. There are several ingress classes like fanout, single service, etc.
            Below is an example ingress resource specification created with two path rules which are pointed to two services:

            Storage Orchestration
            Storage orchestration is the way of Kubernetes handling the storage throughout the cluster. There are two types of storage types available for our applications from Kubernetes.
            Volume
            Persistent Volume
            Volume
            In Kubernetes, each container will have its own isolated file system. Containers can either write or read from this file system. But whenever the container stopped or restarted, this file system will be destroyed and a new file system will be created. To solve this problem we need to use volumes.
            Volume is a filesystem that will be isolated at the pod level. So in the case of a container being restarted or stopped, these volumes will not be destroyed. But the lifetime of the volume is bound by the pod itself. So in the case where a pod gets restarted these volumes will be destroyed and a new volume will be created. So these volumes are not suitable if you want to persist the data. For that, we need to use Persistent Volumes.
            Persistent Volume
            Persistent volumes are long term volumes which we can use in our Kubernetes applications. These persistent volumes exist beyond container or pod, and also beyond nodes itself as well. In a Kubernetes environment, these persistent volumes will be created by an administrator of the cluster, and users such as developers deploying applications can request for persistent volumes by a PersistentVolumeClaim.
            The following are current options available as storage options for Kubernetes.
            AWSElasticBlockStore

        </div>
    </div>
    <div class="footer"><p class="copyright">© 2018-2020 Francis Nana-Dabankah. All rights reserved.</p></div>
</div>
</body>


</html>
